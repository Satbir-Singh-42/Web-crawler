{"file_contents":{"README.md":{"content":"# üïµÔ∏è‚Äç‚ôÇÔ∏è Advanced Phishing Domain Detector\n\nA powerful Flask-based web application that detects and analyzes potential phishing domains by performing comprehensive security checks, SSL validation, domain authentication, content analysis, and AI-powered phishing detection using Google Gemini API with ML model fallback.\n\n## üåü Features\n\n### Core Detection Features\n- **Domain Legitimacy Verification**: Multi-layered domain validation\n- **SSL Certificate Analysis**: Validates SSL certificates from trusted CAs\n- **Domain Authentication**: Checks DMARC, SPF, and security records\n- **WHOIS Analysis**: Examines domain registration details and age\n- **Content Scanning**: Analyzes web content for phishing indicators\n- **Similarity Detection**: Uses Levenshtein distance to identify domain spoofing\n- **Real-time Analysis**: Multi-threaded scanning for efficient detection\n- **Risk Assessment**: Classifies domains as High, Medium, or Low risk\n\n### AI/ML-Powered Features\n- **Google Gemini API Integration**: Advanced AI-powered phishing detection with detailed reasoning\n- **ML Model Fallback**: RandomForest classifier (100% accuracy) when API unavailable\n- **Batch Processing**: Upload Excel files to analyze multiple domains\n- **Feature Extraction**: Analyzes domain length, digits, hyphens, keywords, and structure\n- **Smart Fallback System**: Automatically switches between Gemini API ‚Üí ML model based on availability\n\n## üìã Prerequisites\n\n- Python 3.11+\n- pip (Python package manager)\n- Internet connection for domain checking\n- (Optional) Google Gemini API key for AI-powered detection\n\n## üöÄ Quick Start\n\n### Installation (Linux/macOS/Windows)\n\n1. **Clone the repository**:\n   ```bash\n   git clone https://github.com/param-punjab/web-crawler\n   cd web-crawler\n   ```\n\n2. **Install dependencies**:\n   ```bash\n   pip install -r requirements.txt\n   ```\n\n3. **(Optional)** Set up Google Gemini API:\n   ```bash\n   export GOOGLE_API_KEY=\"your-api-key-here\"\n   ```\n\n4. **Run the application**:\n   ```bash\n   python app.py\n   ```\n\n5. **Access the app**: Open `http://localhost:5000` in your browser\n\n## üìä Dependencies\n\n```txt\nFlask==2.3.3\ntldextract==3.4.4\nbeautifulsoup4==4.12.2\nrequests==2.31.0\npython-whois==0.8.0\ndnspython==2.4.2\njellyfish==1.0.3\nwhois\ngunicorn\nopenpyxl\npandas\nscikit-learn\ngoogle-generativeai\n```\n\n## üéØ Usage\n\n### Web Interface\n\n1. **Traditional Domain Analysis**:\n   - Enter a target domain (e.g., `google.com`)\n   - Click \"Analyze Domain\" to start detection\n   - View results showing potential phishing domains\n   - Export results as JSON or CSV\n\n2. **Quick Domain Check**:\n   - Click \"quick check a specific domain\"\n   - Enter legitimate domain and domain to check\n   - Get instant legitimacy verification\n\n### API Endpoints (Programmatic Access)\n\nThe application provides REST API endpoints for programmatic access:\n\n#### 1. Start Domain Analysis\n```bash\ncurl -X POST http://localhost:5000/analyze \\\n  -H \"Content-Type: application/x-www-form-urlencoded\" \\\n  -d \"domain=example.com\"\n```\n\n#### 2. AI-Powered Phishing Detection\n```bash\ncurl -X POST http://localhost:5000/ml-detect \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"domain\":\"paypal-secure.com\"}'\n```\n\nResponse:\n```json\n{\n  \"classification\": \"Phishing\",\n  \"confidence\": 95.0,\n  \"detection_method\": \"Google Gemini API\",\n  \"domain\": \"paypal-secure.com\",\n  \"is_phishing\": true,\n  \"reasons\": [\n    \"Contains the keyword 'secure', frequently used in phishing\",\n    \"Not the official PayPal domain\",\n    \"Uses hyphen to imitate legitimate services\"\n  ],\n  \"features\": {\n    \"length\": 17,\n    \"has_hyphen\": 1,\n    \"suspicious_keywords\": 1\n  }\n}\n```\n\n#### 3. Quick Domain Legitimacy Check\n```bash\ncurl -X POST http://localhost:5000/check-domain \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"domain\":\"google.com\", \"target_domain\":\"google.com\"}'\n```\n\n#### 4. Batch Detection from Excel\n```bash\ncurl -X POST http://localhost:5000/batch-detect \\\n  -F \"file=@domains.xlsx\"\n```\n\n#### 5. Get Analysis Results\n```bash\ncurl http://localhost:5000/api/analysis/{analysis_id}\n```\n\n## üîç Detection Methods\n\nThe tool uses multiple techniques to identify phishing domains:\n\n1. **Domain Variation Generation**: Creates potential phishing domains using common patterns (prefixes, suffixes, TLD changes)\n2. **SSL Certificate Validation**: Checks certificate validity, expiration, and organization details\n3. **DNS Record Analysis**: Validates security records (DMARC, SPF)\n4. **WHOIS Verification**: Examines domain registration information and age\n5. **Content Analysis**: Scans for login forms and suspicious keywords\n6. **Similarity Comparison**: Measures textual similarity using Levenshtein distance\n7. **AI-Powered Detection**: Google Gemini API analyzes domains with detailed reasoning\n8. **ML Model Classification**: RandomForest model as fallback with feature extraction\n\n## üìÅ Project Structure\n\n```\n.\n‚îú‚îÄ‚îÄ app.py                 # Main Flask application with all endpoints\n‚îú‚îÄ‚îÄ phishing_model.pkl     # Trained RandomForest ML model (100% accuracy)\n‚îú‚îÄ‚îÄ domain_dataset.xlsx    # Training dataset (70 domains: 35 legitimate + 35 phishing)\n‚îú‚îÄ‚îÄ requirements.txt       # Python dependencies\n‚îú‚îÄ‚îÄ .gitignore            # Git ignore rules\n‚îú‚îÄ‚îÄ README.md             # This file\n‚îú‚îÄ‚îÄ DOCUMENTATION.md      # Technical documentation\n‚îî‚îÄ‚îÄ templates/            # HTML templates\n    ‚îú‚îÄ‚îÄ index.html        # Main interface\n    ‚îî‚îÄ‚îÄ results.html      # Results display\n```\n\n## üö¢ Deployment\n\n### Production Deployment\n\nFor production environments, use Gunicorn WSGI server:\n\n```bash\ngunicorn --bind=0.0.0.0:5000 --workers=4 app:app\n```\n\n**Recommended Configuration**:\n- Workers: 2-4 (based on CPU cores)\n- Port: 5000\n- Timeout: 120 seconds (for long-running domain checks)\n- Use reverse proxy (Nginx/Apache) for SSL termination\n\n## ‚öôÔ∏è Configuration\n\n### Environment Variables\n\n| Variable | Required | Description |\n|----------|----------|-------------|\n| `GOOGLE_API_KEY` | Optional | Google Gemini API key for AI-powered detection. If not set, falls back to ML model |\n\n### Development vs Production\n\n**Development** (default when running `python app.py`):\n- Debug mode: Enabled\n- Host: 0.0.0.0\n- Port: 5000\n- Auto-reload: Enabled\n\n**Production** (when using Gunicorn):\n- Debug mode: Disabled\n- Workers: 4\n- Host: 0.0.0.0\n- Port: 5000\n\n## üîê Security Considerations\n\n- Application performs network requests to external domains\n- SSL verification is enabled by default\n- User input is sanitized before processing\n- Session management uses Flask's built-in secret key (change in production!)\n- Google Gemini API key stored in environment variables (never hardcoded)\n\n## ‚ö° Troubleshooting\n\n### Common Issues\n\n**1. ML model not loading:**\n- Ensure `phishing_model.pkl` file exists in project root\n- Check Python version (requires 3.11+)\n\n**2. Google Gemini API not working:**\n- Verify `GOOGLE_API_KEY` environment variable is set\n- Check API key is valid and has quota\n- System automatically falls back to ML model if API unavailable\n\n**3. Domain analysis returns no results:**\n- Check internet connection\n- Verify DNS resolution is working\n- Some domains may not have variations that exist\n\n**4. Port 5000 already in use:**\n- Change port in `app.py`: `app.run(port=5001)`\n- Or kill process using port 5000: `lsof -ti:5000 | xargs kill`\n\n**5. Dependencies installation fails:**\n- Update pip: `pip install --upgrade pip`\n- Install build tools: `apt-get install python3-dev` (Linux)\n\n## üß™ Testing\n\n### Test the Application\n\n1. **Test Frontend**: Open `http://localhost:5000` and analyze a domain\n2. **Test ML Endpoint**: \n   ```bash\n   curl -X POST http://localhost:5000/ml-detect \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"domain\":\"test.com\"}'\n   ```\n3. **Test Quick Check**:\n   ```bash\n   curl -X POST http://localhost:5000/check-domain \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"domain\":\"google.com\",\"target_domain\":\"google.com\"}'\n   ```\n\n### Verify Gemini API Integration\n\n```bash\ncurl -X POST http://localhost:5000/ml-detect \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"domain\":\"paypal-login.com\"}'\n```\n\nLook for `\"detection_method\": \"Google Gemini API\"` in response.\n\n## üìà Performance\n\n- **Average Analysis Time**: 5-15 seconds per target domain\n- **Concurrent Analysis**: Multi-threaded (5 workers)\n- **Domain Variations**: Generates 40+ potential phishing domains\n- **ML Model Accuracy**: 100% on test dataset (70 domains)\n- **API Response Time**: < 2 seconds for ML detection\n\n## üõ£Ô∏è Roadmap\n\n- [ ] Database storage for analysis history\n- [ ] User authentication and session management\n- [ ] Scheduled scanning for monitored domains\n- [ ] Email alerts for detected phishing domains\n- [ ] API rate limiting and caching\n- [ ] Enhanced AI model training with larger datasets\n- [ ] Support for bulk domain list uploads (CSV)\n- [ ] Domain reputation scoring system\n- [ ] Integration with threat intelligence feeds\n\n## ü§ù Contributing\n\n1. Fork the repository\n2. Create a feature branch: `git checkout -b feature-name`\n3. Make your changes and commit: `git commit -m 'Add feature'`\n4. Push to the branch: `git push origin feature-name`\n5. Submit a pull request\n\n## üìù License\n\nThis project is open source and available under the MIT License.\n\n## üë• Authors\n\n- **Original Author**: [param-punjab](https://github.com/param-punjab)\n\n## üôè Acknowledgments\n\n- Google Gemini API for AI-powered phishing detection\n- scikit-learn for machine learning capabilities\n- Flask framework for web application\n- Bootstrap for responsive UI design\n\n## üìß Support\n\n**For support:**\n- Create an issue on GitHub with details about your problem\n- Include error messages, logs, and steps to reproduce\n- Check existing issues first to avoid duplicates\n\n---\n\n**Made with ‚ù§Ô∏è for cybersecurity**\n","size_bytes":9877},"app.py":{"content":"from flask import Flask, render_template, request, jsonify, session, redirect, url_for\nimport tldextract\nimport ssl\nimport socket\nfrom datetime import datetime\nimport whois\nimport requests\nimport re\nimport dns.resolver\nimport threading\nimport uuid\nimport concurrent.futures\nfrom bs4 import BeautifulSoup\nfrom urllib.parse import urlparse, urljoin\nimport jellyfish\nimport pickle\nimport pandas as pd\nimport google.generativeai as genai\nlev_distance = jellyfish.levenshtein_distance\n\napp = Flask(__name__)\napp.secret_key = 'secretkey' \n\nanalysis_results = {}\n\ntry:\n    with open('phishing_model.pkl', 'rb') as f:\n        ml_model = pickle.load(f)\n    print(\"ML model loaded successfully\")\nexcept Exception as e:\n    print(f\"Warning: Could not load ML model: {e}\")\n    ml_model = None\n\ntry:\n    import os\n    api_key = os.environ.get('GOOGLE_API_KEY')\n    if api_key:\n        genai.configure(api_key=api_key)\n        gemini_model = genai.GenerativeModel('gemini-2.0-flash-exp')\n        print(\"Google Gemini API configured successfully\")\n    else:\n        gemini_model = None\n        print(\"Warning: GOOGLE_API_KEY not found in environment variables\")\nexcept Exception as e:\n    print(f\"Warning: Could not configure Gemini API: {e}\")\n    gemini_model = None\n\ndef extract_ml_features(domain):\n    \"\"\"Extract features from domain for ML model\"\"\"\n    features = {}\n    features['length'] = len(domain)\n    features['has_digit'] = int(bool(re.search(r'\\d', domain)))\n    features['has_hyphen'] = int('-' in domain)\n    features['num_dots'] = domain.count('.')\n    features['num_digits'] = sum(c.isdigit() for c in domain)\n    features['suspicious_keywords'] = int(any(kw in domain.lower() for kw in ['login', 'verify', 'secure', 'account', 'update', 'confirm']))\n    features['tld_length'] = len(domain.split('.')[-1]) if '.' in domain else 0\n    features['subdomain_count'] = domain.count('.') - 1 if domain.count('.') > 0 else 0\n    return features\n\ndef validate_gemini_response(result):\n    \"\"\"Validate Gemini API response structure and data\"\"\"\n    if not isinstance(result, dict):\n        return False, \"Response is not a dictionary\"\n    \n    required_fields = ['is_phishing', 'confidence', 'reasons', 'classification']\n    for field in required_fields:\n        if field not in result:\n            return False, f\"Missing required field: {field}\"\n    \n    if not isinstance(result['is_phishing'], bool):\n        return False, \"is_phishing must be a boolean\"\n    \n    if not isinstance(result['confidence'], (int, float)):\n        return False, \"confidence must be a number\"\n    \n    if not (0 <= result['confidence'] <= 100):\n        return False, \"confidence must be between 0 and 100\"\n    \n    if not isinstance(result['reasons'], list):\n        return False, \"reasons must be a list\"\n    \n    if not result['reasons']:\n        return False, \"reasons list cannot be empty\"\n    \n    if result['classification'] not in ['Phishing', 'Legitimate']:\n        return False, f\"Invalid classification: {result['classification']}\"\n    \n    is_phishing_matches = (result['is_phishing'] and result['classification'] == 'Phishing') or \\\n                          (not result['is_phishing'] and result['classification'] == 'Legitimate')\n    if not is_phishing_matches:\n        return False, \"is_phishing and classification fields don't match\"\n    \n    return True, \"Valid\"\n\ndef check_with_gemini(domain):\n    \"\"\"Check domain credibility using Google Gemini API with comprehensive validation\"\"\"\n    if not gemini_model:\n        return None, \"Gemini API not available\"\n    \n    try:\n        prompt = f\"\"\"Analyze this domain for phishing indicators: {domain}\n\nPlease evaluate if this domain is legitimate or potentially a phishing domain. Consider:\n1. Character substitutions (like 0 for O, 1 for l)\n2. Suspicious keywords (login, verify, secure, account)\n3. Domain structure and patterns\n4. Known legitimate domains\n5. TLD (top-level domain) reputation\n\nRespond ONLY in valid JSON format with:\n{{\n  \"is_phishing\": true/false,\n  \"confidence\": 0-100,\n  \"reasons\": [\"reason1\", \"reason2\", \"reason3\"],\n  \"classification\": \"Phishing\" or \"Legitimate\"\n}}\n\nImportant: Provide at least 2-3 specific reasons for your classification.\"\"\"\n\n        response = gemini_model.generate_content(prompt)\n        \n        if not response or not response.text:\n            return None, \"Empty response from Gemini API\"\n        \n        import json\n        result_text = response.text.strip()\n        \n        if result_text.startswith('```json'):\n            result_text = result_text[7:-3].strip()\n        elif result_text.startswith('```'):\n            result_text = result_text[3:-3].strip()\n        \n        try:\n            result = json.loads(result_text)\n        except json.JSONDecodeError as je:\n            return None, f\"Invalid JSON response: {str(je)}\"\n        \n        is_valid, validation_msg = validate_gemini_response(result)\n        if not is_valid:\n            return None, f\"Invalid response format: {validation_msg}\"\n        \n        print(f\"‚úì Gemini API validated: {domain} -> {result['classification']} ({result['confidence']}%)\")\n        return result, None\n        \n    except Exception as e:\n        error_msg = str(e)\n        if 'quota' in error_msg.lower() or 'rate' in error_msg.lower():\n            return None, f\"API quota exceeded: {error_msg}\"\n        elif 'api key' in error_msg.lower():\n            return None, \"Invalid API key\"\n        return None, f\"API error: {error_msg}\"\n\nclass AdvancedDomainChecker:\n    def __init__(self, target_domain):\n        self.target_domain = target_domain\n        self.target_parts = tldextract.extract(self.target_domain)\n        \n    def is_legitimate_domain(self, domain):\n        \"\"\"Check the domain legitimacy using multiple verification methods\"\"\"\n        check_score = 0\n        reasons = []\n        \n        parts = tldextract.extract(domain)\n\n        if parts.registered_domain != self.target_parts.registered_domain:\n            check_score += 1\n            reasons.append(\"Different registered domain\")\n        \n        ssl_valid, ssl_reason = self.has_valid_ssl_certificate(domain)\n        if not ssl_valid:\n            check_score += 1\n            reasons.append(f\"SSL Issue: {ssl_reason}\")\n        \n        auth_valid, auth_reason = self.has_domain_authentication(parts.registered_domain)\n        if not auth_valid:\n            check_score += 1\n            reasons.append(f\"Domain auth issue: {auth_reason}\")\n\n        registration_valid, reg_reason = self.has_legitimate_registration(domain)\n        if not registration_valid:\n            check_score += 1\n            reasons.append(f\"Registration issue: {reg_reason}\")\n        \n        if check_score == 0:\n            return True, \"Domain appears legitimate\"\n        else:\n            return False, \"; \".join(reasons)\n            \n    def has_valid_ssl_certificate(self, domain, port=443):\n        \"\"\"Check if the domain has valid SSL certificate from trusted CA\"\"\"\n        try:\n            context = ssl.create_default_context()\n            with socket.create_connection((domain, port), timeout=5) as sock:\n                with context.wrap_socket(sock, server_hostname=domain) as ssock:\n                    cert = ssock.getpeercert()\n\n                if not cert:\n                    return False, \"No SSL certificate found\"\n                \n                not_after = datetime.strptime(cert['notAfter'], '%b %d %H:%M:%S %Y %Z')\n                if datetime.now() > not_after:\n                    return False, \"SSL certificate expired\"\n\n                org_name = None\n                if 'subject' in cert:\n                    for field in cert['subject']:\n                        if field[0][0] == 'organizationName':\n                            org_name = field[0][1]\n                            break\n\n                if org_name and (\"education\" in org_name.lower() or \"college\" in org_name.lower() \n                                or \"university\" in org_name.lower() or \"gndec\" in org_name.lower()):\n                    return True, f\"Valid educational certificate: {org_name}\"\n                \n                return True, \"Valid SSL certificate\"\n        except Exception as e:\n            return False, f\"SSL connection failed: {str(e)}\"\n    \n    def has_domain_authentication(self, domain):\n        \"\"\"Check for domain authentication records that legitimate organizations typically implement\"\"\"\n        try:\n            dmarc_record = f\"_dmarc.{domain}\"\n            try:\n                answers = dns.resolver.resolve(dmarc_record, 'TXT')\n                for rdata in answers:\n                    if 'v=DMARC1' in str(rdata):\n                        return True, \"DMARC record found\"\n            except:\n                pass\n\n            try:\n                answers = dns.resolver.resolve(domain, 'TXT')\n                for rdata in answers:\n                    if 'v=spf1' in str(rdata):\n                        return True, \"SPF record found\"\n            except:\n                pass\n\n            return False, \"No domain authentication records found\"\n        except Exception as e:\n            return False, f\"DNS checks failed: {str(e)}\"\n    \n    def has_legitimate_registration(self, domain):\n        \"\"\"Check WHOIS information for legitimate registration details\"\"\"\n        try:\n            w = whois.whois(domain)\n            \n            if w.creation_date:\n                if isinstance(w.creation_date, list):\n                    creation_date = w.creation_date[0]\n                else:\n                    creation_date = w.creation_date\n\n                if isinstance(creation_date, str):\n                    try:\n                        creation_date = datetime.strptime(str(creation_date), '%Y-%m-%d %H:%M:%S')\n                    except:\n                        try:\n                            creation_date = datetime.strptime(str(creation_date), '%d-%b-%Y')\n                        except:\n                            return True, \"Could not parse creation date\"\n                elif not isinstance(creation_date, datetime):\n                    return True, \"Could not parse creation date\"\n\n                domain_age = (datetime.now() - creation_date).days\n                if domain_age < 30:\n                    return False, f\"Domain is very new ({domain_age} days)\"\n\n            if domain.endswith('.edu') or domain.endswith('.ac.in'):\n                return True, \"Educational domain detected\"\n\n            return True, \"Domain registration appears legitimate\"\n        except Exception as e:\n            return False, f\"WHOIS check failed: {str(e)}\"\n\nclass PhishingDetector:\n    def __init__(self, target_domain):\n        self.target_domain = target_domain\n        self.checker = AdvancedDomainChecker(target_domain)\n        self.user_agent = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36\"\n        self.session = requests.Session()\n        self.session.headers.update({\"User-Agent\": self.user_agent})\n        \n    def generate_domain_variations(self):\n        \"\"\"Generate potential phishing domains using various techniques\"\"\"\n        variations = set()\n        domain_parts = tldextract.extract(self.target_domain)\n        base_domain = f\"{domain_parts.domain}.{domain_parts.suffix}\"\n        \n        prefixes = ['login', 'signin', 'verify', 'secure', 'account', 'auth']\n        suffixes = ['login', 'signin', 'verify', 'secure', 'account', 'auth']\n        \n        for prefix in prefixes:\n            variations.add(f\"{prefix}-{base_domain}\")\n            variations.add(f\"{prefix}.{base_domain}\")\n            variations.add(f\"{prefix}{base_domain}\")\n            \n        for suffix in suffixes:\n            variations.add(f\"{base_domain}-{suffix}\")\n            variations.add(f\"{base_domain}.{suffix}\")\n            variations.add(f\"{base_domain}{suffix}\")\n            \n        if domain_parts.suffix == 'com':\n            for tld in ['net', 'org', 'info', 'biz']:\n                variations.add(f\"{domain_parts.domain}.{tld}\")\n                \n        return variations\n        \n    def get_suspicious_domains(self):\n        \"\"\"Get all suspicious domains from various sources\"\"\"\n        print(\"Searching for suspicious domains...\")\n        \n        generated_domains = self.generate_domain_variations()\n        print(f\"Generated {len(generated_domains)} domain variations\")\n        \n        valid_domains = []\n        for domain in generated_domains:\n            if self.validate_domain_exists(domain):\n                valid_domains.append(domain)\n                \n        print(f\"Found {len(valid_domains)} valid domains to check\")\n        return valid_domains\n        \n    def validate_domain_exists(self, domain):\n        \"\"\"Check if a domain actually exists by resolving DNS\"\"\"\n        try:\n            dns.resolver.resolve(domain, 'A')\n            return True\n        except:\n            return False\n            \n    def analyze_domain(self, domain):\n        \"\"\"Analyze a single domain for phishing indicators\"\"\"\n        risk_factors = []\n        final_url = domain\n        title = \"\"\n        \n        is_legitimate, reason = self.checker.is_legitimate_domain(domain)\n        if not is_legitimate:\n            risk_factors.append(f\"Legitimacy check failed: {reason}\")\n        \n        try:\n            response = self.session.get(f\"https://{domain}\", timeout=10, allow_redirects=True)\n            final_url = response.url\n            content = response.text\n            \n            soup = BeautifulSoup(content, 'html.parser')\n            \n            title_tag = soup.find('title')\n            if title_tag:\n                title = title_tag.get_text().strip()\n                \n            login_forms = soup.find_all('form')\n            for form in login_forms:\n                inputs = form.find_all('input')\n                has_password = any(input.get('type') == 'password' for input in inputs)\n                has_username = any(input.get('type') in ['text', 'email'] for input in inputs)\n                \n                if has_password and has_username:\n                    risk_factors.append(\"Contains login form with username and password fields\")\n                    break\n            \n            suspicious_keywords = ['login', 'signin', 'verify', 'account', 'security']\n            content_lower = content.lower()\n            \n            if title:\n                title_lower = title.lower()\n                if any(keyword in title_lower for keyword in suspicious_keywords):\n                    risk_factors.append(\"Uses suspicious keywords in title\")\n            \n            keyword_count = 0\n            for keyword in suspicious_keywords:\n                if keyword in content_lower:\n                    keyword_count += 1\n            \n            if keyword_count > 3:\n                risk_factors.append(f\"Uses multiple ({keyword_count}) suspicious keywords in content\")\n                \n            target_clean = self.target_domain.replace('www.', '').replace('.com', '')\n            domain_clean = domain.replace('www.', '').replace('.com', '')\n            \n            similarity = lev_distance(target_clean, domain_clean)\n            if similarity <= 2:\n                risk_factors.append(f\"Very similar to target domain (distance: {similarity})\")\n                \n        except Exception as e:\n            risk_factors.append(f\"Cannot access website: {str(e)}\")\n        \n        risk_level = self.determine_risk_level(risk_factors)\n        \n        return risk_factors, final_url, title, risk_level\n        \n    def determine_risk_level(self, risk_factors):\n        \"\"\"Determine risk level based on factors found\"\"\"\n        if not risk_factors:\n            return \"Low\"\n        \n        high_risk_indicators = [\n            \"SSL certificate is invalid or expired\",\n            \"Contains login form with username and password fields\",\n            \"Legitimacy check failed:\"\n        ]\n        \n        medium_risk_indicators = [\n            \"Uses HTTP instead of HTTPS\",\n            \"Uses multiple (\",\n            \"Recently registered domain (\",\n            \"Very similar to target domain\"\n        ]\n        \n        high_count = sum(1 for factor in risk_factors if any(indicator in factor for indicator in high_risk_indicators))\n        medium_count = sum(1 for factor in risk_factors if any(indicator in factor for indicator in medium_risk_indicators))\n        \n        if high_count > 0:\n            return \"High\"\n        elif medium_count > 1 or (medium_count > 0 and len(risk_factors) > 2):\n            return \"Medium\"\n        else:\n            return \"Low\"\n\n@app.route('/')\ndef index():\n    return render_template('index.html')\n\n@app.route('/analyze', methods=['POST'])\ndef analyze():\n    target_domain = request.form.get('domain')\n    if not target_domain:\n        return jsonify({'success': False, 'error': 'Please enter a domain name'})\n    \n    if not target_domain.startswith(('http://', 'https://')):\n        target_domain = 'https://' + target_domain\n    \n    parsed_domain = urlparse(target_domain)\n    netloc = parsed_domain.netloc or parsed_domain.path\n    \n    analysis_id = str(uuid.uuid4())\n    \n    analysis_results[analysis_id] = {\n        'target_domain': netloc,\n        'status': 'processing',\n        'progress': 0,\n        'results': [],\n        'start_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n        'end_time': None,\n        'total_domains': 0,\n        'processed_domains': 0\n    }\n    \n    thread = threading.Thread(target=run_analysis, args=(netloc, analysis_id))\n    thread.daemon = True\n    thread.start()\n    \n    return jsonify({\n        'success': True,\n        'analysis_id': analysis_id,\n        'redirect_url': f'/results/{analysis_id}'\n    })\n\ndef run_analysis(target_domain, analysis_id):\n    \"\"\"Run the analysis and store results with progress updates\"\"\"\n    detector = PhishingDetector(target_domain)\n    \n    analysis_results[analysis_id]['status'] = 'searching_domains'\n    analysis_results[analysis_id]['progress'] = 20\n    \n    suspicious_domains = detector.get_suspicious_domains()\n    \n    if not suspicious_domains:\n        analysis_results[analysis_id]['status'] = 'completed'\n        analysis_results[analysis_id]['progress'] = 100\n        analysis_results[analysis_id]['end_time'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n        return\n    \n    analysis_results[analysis_id]['status'] = 'analyzing_domains'\n    analysis_results[analysis_id]['progress'] = 40\n    analysis_results[analysis_id]['total_domains'] = len(suspicious_domains)\n    analysis_results[analysis_id]['processed_domains'] = 0\n    \n    results = []\n    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n        future_to_domain = {executor.submit(detector.analyze_domain, domain): domain for domain in suspicious_domains}\n        \n        for i, future in enumerate(concurrent.futures.as_completed(future_to_domain)):\n            domain = future_to_domain[future]\n            try:\n                risk_factors, final_url, title, risk_level = future.result()\n                \n                if risk_factors:\n                    results.append({\n                        \"domain\": domain,\n                        \"url\": final_url,\n                        \"title\": title,\n                        \"risk_factors\": risk_factors,\n                        \"risk_level\": risk_level\n                    })\n                \n                analysis_results[analysis_id]['processed_domains'] = i + 1\n                analysis_results[analysis_id]['progress'] = 40 + (i / len(suspicious_domains)) * 60\n                analysis_results[analysis_id]['results'] = results\n                \n            except Exception as e:\n                print(f\"Error analyzing {domain}: {e}\")\n    \n    analysis_results[analysis_id]['status'] = 'completed'\n    analysis_results[analysis_id]['progress'] = 100\n    analysis_results[analysis_id]['results'] = results\n    analysis_results[analysis_id]['end_time'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n\n@app.route('/results/<analysis_id>')\ndef results(analysis_id):\n    if analysis_id not in analysis_results:\n        return redirect(url_for('index'))\n    \n    return render_template('results.html', analysis_id=analysis_id)\n\n@app.route('/api/analysis/<analysis_id>')\ndef get_analysis(analysis_id):\n    if analysis_id not in analysis_results:\n        return jsonify({'error': 'Analysis not found'}), 404\n    \n    return jsonify(analysis_results[analysis_id])\n\n@app.route('/check-domain', methods=['POST'])\ndef check_domain():\n    \"\"\"Check a single domain for legitimacy\"\"\"\n    data = request.get_json()\n    domain = data.get('domain')\n    target_domain = data.get('target_domain')\n    \n    if not domain or not target_domain:\n        return jsonify({'error': 'Domain and target domain are required'}), 400\n    \n    checker = AdvancedDomainChecker(target_domain)\n    is_legitimate, reason = checker.is_legitimate_domain(domain)\n    \n    return jsonify({\n        'domain': domain,\n        'is_legitimate': is_legitimate,\n        'reason': reason\n    })\n\ndef cross_validate_results(domain, gemini_result, ml_prediction, ml_probability):\n    \"\"\"Cross-validate Gemini and ML model results for consistency\"\"\"\n    gemini_is_phishing = gemini_result.get('is_phishing', False)\n    gemini_confidence = gemini_result.get('confidence', 0)\n    \n    ml_is_phishing = bool(ml_prediction == 1)\n    ml_confidence = float(ml_probability[int(ml_prediction)]) * 100\n    \n    agreement = gemini_is_phishing == ml_is_phishing\n    \n    validation_result = {\n        'agreement': agreement,\n        'gemini_classification': 'Phishing' if gemini_is_phishing else 'Legitimate',\n        'ml_classification': 'Phishing' if ml_is_phishing else 'Legitimate',\n        'gemini_confidence': gemini_confidence,\n        'ml_confidence': ml_confidence,\n        'confidence_difference': abs(gemini_confidence - ml_confidence)\n    }\n    \n    if agreement:\n        validation_result['status'] = 'Both models agree'\n        if abs(gemini_confidence - ml_confidence) < 20:\n            validation_result['reliability'] = 'High'\n        else:\n            validation_result['reliability'] = 'Medium'\n    else:\n        validation_result['status'] = 'Models disagree - requires manual review'\n        validation_result['reliability'] = 'Low'\n        validation_result['warning'] = f\"Gemini says {validation_result['gemini_classification']}, ML says {validation_result['ml_classification']}\"\n    \n    print(f\"Cross-validation for {domain}: {validation_result['status']} (Reliability: {validation_result['reliability']})\")\n    return validation_result\n\n@app.route('/ml-detect', methods=['POST'])\ndef ml_detect():\n    \"\"\"Detect phishing domain using Gemini API with ML model fallback and cross-validation\"\"\"\n    data = request.get_json()\n    domain = data.get('domain')\n    \n    if not domain:\n        return jsonify({'error': 'Domain is required'}), 400\n    \n    domain_clean = domain.replace('http://', '').replace('https://', '').split('/')[0]\n    \n    gemini_result, gemini_error = check_with_gemini(domain_clean)\n    features = extract_ml_features(domain_clean)\n    \n    if gemini_result and ml_model:\n        try:\n            feature_columns = ['length', 'has_digit', 'has_hyphen', 'num_dots', 'num_digits', 'suspicious_keywords', 'tld_length', 'subdomain_count']\n            feature_values = [features[col] for col in feature_columns]\n            \n            ml_prediction = ml_model.predict([feature_values])[0]\n            ml_probability = ml_model.predict_proba([feature_values])[0]\n            \n            cross_validation = cross_validate_results(domain_clean, gemini_result, ml_prediction, ml_probability)\n            \n            result = {\n                'domain': domain_clean,\n                'is_phishing': gemini_result.get('is_phishing', False),\n                'confidence': float(gemini_result.get('confidence', 0)),\n                'classification': gemini_result.get('classification', 'Unknown'),\n                'reasons': gemini_result.get('reasons', []),\n                'detection_method': 'Google Gemini API (Cross-validated with ML)',\n                'features': features,\n                'cross_validation': cross_validation\n            }\n            return jsonify(result)\n        except Exception as e:\n            print(f\"Cross-validation failed: {e}\")\n    \n    if gemini_result:\n        result = {\n            'domain': domain_clean,\n            'is_phishing': gemini_result.get('is_phishing', False),\n            'confidence': float(gemini_result.get('confidence', 0)),\n            'classification': gemini_result.get('classification', 'Unknown'),\n            'reasons': gemini_result.get('reasons', []),\n            'detection_method': 'Google Gemini API',\n            'features': features\n        }\n        return jsonify(result)\n    \n    if ml_model is None:\n        return jsonify({\n            'error': 'Both Gemini API and ML model unavailable',\n            'gemini_error': gemini_error\n        }), 500\n    \n    try:\n        features = extract_ml_features(domain_clean)\n        feature_columns = ['length', 'has_digit', 'has_hyphen', 'num_dots', 'num_digits', 'suspicious_keywords', 'tld_length', 'subdomain_count']\n        feature_values = [features[col] for col in feature_columns]\n        \n        prediction = ml_model.predict([feature_values])[0]\n        probability = ml_model.predict_proba([feature_values])[0]\n        \n        is_phishing = bool(prediction == 1)\n        confidence = float(probability[int(prediction)]) * 100\n        \n        result = {\n            'domain': domain_clean,\n            'is_phishing': is_phishing,\n            'confidence': confidence,\n            'classification': 'Phishing' if is_phishing else 'Legitimate',\n            'detection_method': 'ML Model (Fallback)',\n            'gemini_error': gemini_error,\n            'features': features\n        }\n        \n        return jsonify(result)\n    \n    except Exception as e:\n        return jsonify({'error': f'Error processing domain: {str(e)}'}), 500\n\n@app.route('/batch-detect', methods=['POST'])\ndef batch_detect():\n    \"\"\"Batch detect phishing domains using Gemini API with ML model fallback\"\"\"\n    if 'file' not in request.files:\n        return jsonify({'error': 'No file uploaded'}), 400\n    \n    file = request.files['file']\n    if file.filename == '':\n        return jsonify({'error': 'No file selected'}), 400\n    \n    if not file.filename.endswith(('.xlsx', '.xls')):\n        return jsonify({'error': 'File must be Excel format (.xlsx or .xls)'}), 400\n    \n    try:\n        df = pd.read_excel(file)\n        \n        if 'domain' not in df.columns:\n            return jsonify({'error': 'Excel file must have a \"domain\" column'}), 400\n        \n        results = []\n        gemini_count = 0\n        ml_count = 0\n        \n        for domain in df['domain']:\n            domain_clean = str(domain).replace('http://', '').replace('https://', '').split('/')[0]\n            \n            gemini_result, gemini_error = check_with_gemini(domain_clean)\n            \n            if gemini_result:\n                results.append({\n                    'domain': domain_clean,\n                    'is_phishing': gemini_result.get('is_phishing', False),\n                    'confidence': float(gemini_result.get('confidence', 0)),\n                    'classification': gemini_result.get('classification', 'Unknown'),\n                    'detection_method': 'Gemini API'\n                })\n                gemini_count += 1\n            elif ml_model:\n                features = extract_ml_features(domain_clean)\n                feature_columns = ['length', 'has_digit', 'has_hyphen', 'num_dots', 'num_digits', 'suspicious_keywords', 'tld_length', 'subdomain_count']\n                feature_values = [features[col] for col in feature_columns]\n                \n                prediction = ml_model.predict([feature_values])[0]\n                probability = ml_model.predict_proba([feature_values])[0]\n                \n                is_phishing = bool(prediction == 1)\n                confidence = float(probability[int(prediction)]) * 100\n                \n                results.append({\n                    'domain': domain_clean,\n                    'is_phishing': is_phishing,\n                    'confidence': confidence,\n                    'classification': 'Phishing' if is_phishing else 'Legitimate',\n                    'detection_method': 'ML Model'\n                })\n                ml_count += 1\n            else:\n                results.append({\n                    'domain': domain_clean,\n                    'error': 'Both Gemini API and ML model unavailable'\n                })\n        \n        return jsonify({\n            'results': results, \n            'total': len(results),\n            'gemini_count': gemini_count,\n            'ml_count': ml_count\n        })\n    \n    except Exception as e:\n        return jsonify({'error': f'Error processing file: {str(e)}'}), 500\n\nif __name__ == '__main__':\n    app.run(host='0.0.0.0', port=5000, debug=True, threaded=True)\n","size_bytes":29026},"replit.md":{"content":"# Phishing Domain Detector\n\n## Overview\n\nA Flask-based web application that detects and analyzes potential phishing domains through comprehensive security checks, SSL validation, domain authentication, and AI/ML-powered content analysis. The system uses Google Gemini API with a RandomForest ML fallback to provide intelligent phishing detection with detailed risk assessment.\n\n## Recent Changes (October 3, 2025)\n\n### GitHub Import Setup - Completed\n- **Python Environment**: Python 3.11 installed and configured\n- **Dependencies**: Successfully installed all required packages from requirements.txt (Flask, scikit-learn, pandas, google-generativeai, and all other dependencies)\n- **Requirements Cleanup**: Removed duplicate entries from requirements.txt for cleaner package management\n- **Workflow Configuration**: Set up Flask App workflow to run on `0.0.0.0:5000` with webview output\n- **Deployment Configuration**: Configured production deployment with Gunicorn using autoscale deployment target with 4 workers and 120-second timeout\n- **Application Status**: Successfully running and tested - frontend loads correctly\n\n### Environment Setup\n- **Development Server**: Flask development server running on port 5000 with debug mode enabled\n- **Production Server**: Gunicorn configured with 4 workers, port reuse, and extended timeout for long-running domain checks\n- **ML Model**: phishing_model.pkl loaded successfully on startup\n- **API Integration**: Google Gemini API ready (requires GOOGLE_API_KEY environment variable to be set by user)\n\n### Configuration Notes\n- To use Google Gemini API for advanced AI-powered detection, add GOOGLE_API_KEY to environment variables\n- Without API key, application automatically falls back to RandomForest ML model\n- Application binds to 0.0.0.0:5000 for Replit proxy compatibility\n\n## User Preferences\n\nPreferred communication style: Simple, everyday language.\n\n## System Architecture\n\n### Core Application Framework\n\n**Flask Web Application**: The system is built on Flask 2.3.3, following a traditional server-side rendering pattern with:\n- Route handlers in `app.py` for domain analysis and results display\n- Session-based state management for analysis results storage\n- Template rendering with Bootstrap 5 for responsive UI\n- RESTful API endpoints for programmatic access (ML detection endpoints)\n\n**Deployment Strategy**: Configured for both development (`python app.py`) and production (Gunicorn with autoscaling), binding to `0.0.0.0:5000` for web accessibility.\n\n### AI/ML Detection Architecture\n\n**Dual-Layer Intelligence System**: The application implements a smart fallback mechanism:\n\n1. **Primary**: Google Gemini API (`gemini-2.0-flash-exp`) for advanced AI-powered phishing detection with natural language reasoning\n2. **Fallback**: RandomForest ML classifier (100% accuracy on training set) loaded from `phishing_model.pkl`\n\n**Feature Engineering**: Domain analysis extracts structural features including:\n- Domain length, digit count, hyphen presence\n- Keyword analysis for phishing indicators\n- String similarity detection using Levenshtein distance\n- Multi-threaded concurrent analysis for performance\n\n### Domain Validation Pipeline\n\n**Multi-Layer Security Checks**: The system performs comprehensive validation through:\n\n1. **SSL Certificate Analysis**: Validates certificates against trusted Certificate Authorities\n2. **Domain Authentication**: Checks DMARC, SPF, and DNS security records using `dnspython`\n3. **WHOIS Analysis**: Examines domain registration age and ownership details\n4. **Content Scanning**: BeautifulSoup-based HTML parsing for phishing pattern detection\n5. **Similarity Detection**: Jellyfish library for domain spoofing identification\n\n**Result Aggregation**: Analysis results stored in-memory dictionary with UUID-based session tracking, providing risk classification (High/Medium/Low).\n\n### Data Processing\n\n**Batch Analysis**: Supports Excel file uploads for multi-domain analysis using pandas and openpyxl, enabling enterprise-scale phishing detection workflows.\n\n**Model Training**: ML model trained on 70-domain dataset (35 legitimate, 35 phishing) using scikit-learn, achieving perfect accuracy on test set.\n\n## External Dependencies\n\n### AI/ML Services\n- **Google Gemini API**: Primary AI detection service (requires `GOOGLE_API_KEY` environment variable)\n- **scikit-learn**: RandomForest ML model training and inference\n- **pandas**: Excel data processing and feature extraction\n- **openpyxl**: Excel file I/O operations\n\n### Security & Network Libraries\n- **tldextract**: Top-level domain parsing and extraction\n- **python-whois**: WHOIS protocol implementation\n- **dnspython**: DNS record resolution and validation\n- **requests**: HTTP client for domain accessibility checks\n- **beautifulsoup4**: HTML parsing and content analysis\n\n### Utility Libraries\n- **jellyfish**: String similarity algorithms (Levenshtein distance)\n- **Flask**: Web framework with session management\n- **Gunicorn**: Production WSGI server with autoscaling\n\n### Frontend Stack\n- **Bootstrap 5.1.3**: Responsive UI framework\n- **Font Awesome 6.0.0**: Icon library\n- **Native JavaScript**: Form handling and API interactions","size_bytes":5194},"load_kaggle_dataset.py":{"content":"import kagglehub\nimport pandas as pd\nimport os\n\ndef load_phishing_dataset():\n    \"\"\"Load phishing dataset from Kaggle\"\"\"\n    print(\"Downloading phishing dataset from Kaggle...\")\n    \n    try:\n        path = kagglehub.dataset_download(\"taruntiwarihp/phishing-site-urls\")\n        print(f\"Dataset downloaded to: {path}\")\n        \n        csv_files = [f for f in os.listdir(path) if f.endswith('.csv')]\n        print(f\"Found CSV files: {csv_files}\")\n        \n        if not csv_files:\n            print(\"No CSV files found in the dataset\")\n            return None\n        \n        csv_path = os.path.join(path, csv_files[0])\n        print(f\"Loading: {csv_path}\")\n        \n        df = pd.read_csv(csv_path)\n        \n        print(f\"\\nDataset loaded successfully!\")\n        print(f\"Total records: {len(df)}\")\n        print(f\"Columns: {df.columns.tolist()}\")\n        print(\"\\nFirst 5 records:\")\n        print(df.head())\n        \n        print(\"\\nDataset info:\")\n        print(df.info())\n        \n        print(\"\\nLabel distribution:\")\n        if 'Label' in df.columns:\n            print(df['Label'].value_counts())\n        \n        df.to_csv('kaggle_phishing_dataset.csv', index=False)\n        print(\"\\nDataset saved to: kaggle_phishing_dataset.csv\")\n        \n        return df\n        \n    except Exception as e:\n        print(f\"Error loading dataset: {e}\")\n        print(\"\\nNote: You may need to authenticate with Kaggle.\")\n        print(\"Set up Kaggle API credentials:\")\n        print(\"1. Go to https://www.kaggle.com/account\")\n        print(\"2. Create an API token (downloads kaggle.json)\")\n        print(\"3. Set KAGGLE_USERNAME and KAGGLE_KEY environment variables\")\n        return None\n\nif __name__ == \"__main__\":\n    df = load_phishing_dataset()\n","size_bytes":1747}},"version":1}