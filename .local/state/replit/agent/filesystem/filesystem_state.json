{"file_contents":{"README.md":{"content":"# 🕵️‍♂️ Phishing Domain Detector\n\nA powerful Flask web application that detects phishing domains using AI and machine learning. Features Google Gemini API integration with ML model fallback for intelligent phishing detection with detailed risk assessment.\n\n## ✨ Features\n\n### Detection Capabilities\n- 🔍 **AI-Powered Detection** - Google Gemini API analyzes domains with detailed reasoning\n- 🤖 **ML Model Fallback** - RandomForest classifier for when API is unavailable\n- 🔒 **SSL Certificate Validation** - Checks certificate validity and trusted CAs\n- 📧 **Domain Authentication** - Validates DMARC, SPF, and DNS security records\n- 🌐 **WHOIS Analysis** - Examines domain registration and age\n- 📝 **Content Scanning** - Analyzes web content for phishing patterns\n- 📊 **Batch Processing** - Upload Excel files to analyze multiple domains\n- ⚡ **Real-time Analysis** - Multi-threaded concurrent scanning\n\n## 🚀 Quick Start\n\n### 1. Install Dependencies (First Time Only)\n\nIf dependencies aren't installed, run in the Shell:\n```bash\npip install -r requirements.txt\n```\n\n### 2. Environment Setup (Recommended)\n\nFor AI-powered detection, add your Google Gemini API key:\n\n1. Click on **Secrets** (🔒 icon) in the left sidebar\n2. Add a new secret:\n   - Key: `GOOGLE_API_KEY`\n   - Value: Your Google Gemini API key ([Get one here](https://makersuite.google.com/app/apikey))\n\n**Note**: The app works without the API key using the ML model fallback, but Gemini provides more detailed analysis.\n\n### 3. Run the Application\n\nClick the **Run** button at the top. The app will:\n- ✅ Load the ML model (phishing_model.pkl)\n- ✅ Configure Google Gemini API (if key provided)\n- ✅ Start Flask server on port 5000\n\n### 4. Access the Web Interface\n\nThe web preview will open automatically showing the phishing detector interface.\n\n## 📖 How to Use\n\n### Web Interface\n\n1. **Analyze Domain for Phishing Variations**\n   - Enter a legitimate domain (e.g., `paypal.com`)\n   - Click \"Analyze Domain\"\n   - View potential phishing domains found\n\n2. **Quick Domain Check**\n   - Click \"quick check a specific domain\"\n   - Enter the legitimate domain and domain to check\n   - Get instant verification results\n\n### API Endpoints\n\n#### 1. AI-Powered Detection\n```bash\ncurl -X POST https://your-repl-url.repl.co/ml-detect \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"domain\":\"paypal-login-secure.com\"}'\n```\n\n**Response:**\n```json\n{\n  \"domain\": \"paypal-login-secure.com\",\n  \"is_phishing\": true,\n  \"confidence\": 95.0,\n  \"classification\": \"Phishing\",\n  \"detection_method\": \"Google Gemini API\",\n  \"reasons\": [\n    \"Contains suspicious keywords 'login' and 'secure'\",\n    \"Uses hyphens to imitate PayPal\",\n    \"Not the official PayPal domain\"\n  ],\n  \"features\": {\n    \"length\": 23,\n    \"has_hyphen\": 1,\n    \"suspicious_keywords\": 1\n  }\n}\n```\n\n#### 2. Quick Domain Check\n```bash\ncurl -X POST https://your-repl-url.repl.co/check-domain \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"domain\":\"google.com\", \"target_domain\":\"google.com\"}'\n```\n\n#### 3. Batch Detection (Excel Upload)\n```bash\ncurl -X POST https://your-repl-url.repl.co/batch-detect \\\n  -F \"file=@domains.xlsx\"\n```\n\nExcel file should have a column named `domain` with one domain per row.\n\n#### 4. Get Analysis Results\n```bash\ncurl https://your-repl-url.repl.co/api/analysis/{analysis_id}\n```\n\n## 🔧 How It Works\n\n### Detection Pipeline\n\n1. **Domain Variation Generation**\n   - Creates potential phishing domains using common patterns\n   - Adds prefixes/suffixes: `login-`, `secure-`, `-verify`, etc.\n   - Tests alternative TLDs: `.net`, `.org`, `.info`\n\n2. **Multi-Layer Validation**\n   - SSL certificate verification\n   - DNS record analysis (DMARC, SPF)\n   - WHOIS registration checks\n   - Content scanning for login forms\n\n3. **AI Analysis**\n   - **Primary**: Google Gemini API analyzes domain structure and patterns\n   - **Fallback**: ML model uses 8 features (length, digits, hyphens, keywords, etc.)\n   - **Cross-Validation**: Both models compare results for reliability\n\n4. **Risk Classification**\n   - **High Risk**: Multiple red flags (invalid SSL, login forms, new domain)\n   - **Medium Risk**: Some suspicious indicators\n   - **Low Risk**: Minimal or no concerning patterns\n\n## 📁 Project Structure\n\n```\n.\n├── app.py                           # Main Flask application\n├── phishing_model.pkl               # Trained ML model\n├── kaggle_phishing_dataset.csv      # Dataset (549K+ records)\n├── load_kaggle_dataset.py           # Utility to update dataset\n├── requirements.txt                 # Python dependencies\n├── .env.example                     # Environment variables template\n├── templates/\n│   ├── index.html                   # Main interface\n│   └── results.html                 # Results display\n└── README.md                        # This file\n```\n\n## 🔐 Environment Variables\n\nCreate a `.env` file:\n\n| Variable | Required | Description |\n|----------|----------|-------------|\n| `GOOGLE_API_KEY` | Yes | Google Gemini API key for AI detection |\n| `SECRET_KEY` | Optional | Flask session secret (auto-generated if not set) |\n| `KAGGLE_USERNAME` | Optional | For downloading/updating the dataset |\n| `KAGGLE_KEY` | Optional | Kaggle API key for dataset access |\n\n### Getting API Keys\n\n**Google Gemini API:**\n1. Go to [Google AI Studio](https://makersuite.google.com/app/apikey)\n2. Click \"Get API Key\"\n3. Create a new API key\n4. Add to as `GOOGLE_API_KEY`\n\n**Kaggle API (Optional):**\n1. Go to [Kaggle Account Settings](https://www.kaggle.com/account)\n2. Scroll to \"API\" section\n3. Click \"Create New API Token\"\n\n## 🚢 Deployment\n\n### Configuration\n- **Development**: Flask debug server on port 5000\n- **Production**: Gunicorn WSGI server with autoscaling\n\n## 📊 Dataset\n\nThe app includes a Kaggle phishing dataset with 549K+ records:\n- Column `URL`: Domain/URL to check\n- Column `Label`: `bad` (phishing) or `good` (legitimate)\n\nTo update the dataset:\n```bash\npython load_kaggle_dataset.py\n```\n\n## 🧪 Testing\n\n### Test AI Detection\n```bash\ncurl -X POST http://localhost:5000/ml-detect \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"domain\":\"paypal-secure.com\"}'\n```\n\n### Test Domain Analysis\n1. Open the web interface\n2. Enter a domain like `google.com`\n3. Click \"Analyze Domain\"\n4. View results showing potential phishing domains\n\n## ⚙️ Technical Details\n\n### Dependencies\n- **Flask 2.3.3** - Web framework\n- **Google Generative AI** - Gemini API integration\n- **scikit-learn** - ML model (RandomForest)\n- **pandas** - Data processing\n- **dnspython** - DNS validation\n- **python-whois** - Domain registration lookup\n- **BeautifulSoup4** - HTML content analysis\n- **jellyfish** - String similarity (Levenshtein distance)\n\n### ML Model Features\n1. Domain length\n2. Has digits (0/1)\n3. Has hyphens (0/1)\n4. Number of dots\n5. Number of digits\n6. Suspicious keywords count\n7. TLD length\n8. Subdomain count\n\n## 🔍 Troubleshooting\n\n### \"ML model loaded successfully\" but Gemini API not working\n- Check if `GOOGLE_API_KEY` is set in env\n- Verify the API key is valid at [Google AI Studio](https://makersuite.google.com/app/apikey)\n- The app will automatically use the ML model fallback\n\n### Port 5000 already in use\n- Automatically handles port assignment\n- The app is configured to use `0.0.0.0:5000`\n\n### LSP import warnings\n- These are false positives from the language server\n- All packages are installed and working correctly\n- The app runs without any actual errors\n\n### No results from domain analysis\n- Check internet connection\n- Some domains may not have existing variations\n- Try a popular domain like `paypal.com` or `google.com`\n\n## 📈 Performance\n\n- **Analysis Time**: 5-15 seconds per domain\n- **Concurrent Processing**: 5 worker threads\n- **Dataset Size**: 549K+ phishing records\n- **ML Model Accuracy**: High accuracy on test set\n- **API Response**: < 2 seconds for detection\n\n## 🤝 Contributing\n\n1. Fork the repository\n2. Create a feature branch: `git checkout -b feature-name`\n3. Commit changes: `git commit -m 'Add feature'`\n4. Push to branch: `git push origin feature-name`\n5. Submit a pull request\n\n## 📝 License\n\nThis project is open source and available under the MIT License.\n\n## 👨‍💻 Author\n\nOriginal Author: [param-punjab](https://github.com/param-punjab)\n\n## 🙏 Acknowledgments\n\n- Google Gemini API for AI-powered detection\n- Kaggle for phishing datasets\n- scikit-learn for ML capabilities\n- Flask framework for web application\n\n---\n\n**Made for cybersecurity research and education** 🔒\n","size_bytes":8597},"app.py":{"content":"from flask import Flask, render_template, request, jsonify, session, redirect, url_for\nimport tldextract\nimport ssl\nimport socket\nfrom datetime import datetime\nimport whois\nimport requests\nimport re\nimport dns.resolver\nimport threading\nimport uuid\nimport concurrent.futures\nfrom bs4 import BeautifulSoup\nfrom urllib.parse import urlparse, urljoin\nimport jellyfish\nimport pickle\nimport pandas as pd\nimport os\nimport google.generativeai as genai\nlev_distance = jellyfish.levenshtein_distance\n\napp = Flask(__name__)\napp.secret_key = os.environ.get('SECRET_KEY', 'dev-secret-key-change-in-production') \n\nanalysis_results = {}\n\ntry:\n    with open('phishing_model.pkl', 'rb') as f:\n        ml_model = pickle.load(f)\n    print(\"ML model loaded successfully\")\nexcept Exception as e:\n    print(f\"Warning: Could not load ML model: {e}\")\n    ml_model = None\n\ntry:\n    api_key = os.environ.get('GOOGLE_API_KEY')\n    if api_key:\n        genai.configure(api_key=api_key)\n        gemini_model = genai.GenerativeModel('gemini-2.0-flash-exp')\n        print(\"Google Gemini API configured successfully\")\n    else:\n        gemini_model = None\n        print(\"Warning: GOOGLE_API_KEY not found in environment variables\")\nexcept Exception as e:\n    print(f\"Warning: Could not configure Gemini API: {e}\")\n    gemini_model = None\n\ndef extract_ml_features(domain):\n    \"\"\"Extract features from domain for ML model\"\"\"\n    features = {}\n    features['length'] = len(domain)\n    features['has_digit'] = int(bool(re.search(r'\\d', domain)))\n    features['has_hyphen'] = int('-' in domain)\n    features['num_dots'] = domain.count('.')\n    features['num_digits'] = sum(c.isdigit() for c in domain)\n    features['suspicious_keywords'] = int(any(kw in domain.lower() for kw in ['login', 'verify', 'secure', 'account', 'update', 'confirm']))\n    features['tld_length'] = len(domain.split('.')[-1]) if '.' in domain else 0\n    features['subdomain_count'] = domain.count('.') - 1 if domain.count('.') > 0 else 0\n    return features\n\ndef validate_gemini_response(result):\n    \"\"\"Validate Gemini API response structure and data\"\"\"\n    if not isinstance(result, dict):\n        return False, \"Response is not a dictionary\"\n    \n    required_fields = ['is_phishing', 'confidence', 'reasons', 'classification']\n    for field in required_fields:\n        if field not in result:\n            return False, f\"Missing required field: {field}\"\n    \n    if not isinstance(result['is_phishing'], bool):\n        return False, \"is_phishing must be a boolean\"\n    \n    if not isinstance(result['confidence'], (int, float)):\n        return False, \"confidence must be a number\"\n    \n    if not (0 <= result['confidence'] <= 100):\n        return False, \"confidence must be between 0 and 100\"\n    \n    if not isinstance(result['reasons'], list):\n        return False, \"reasons must be a list\"\n    \n    if not result['reasons']:\n        return False, \"reasons list cannot be empty\"\n    \n    if result['classification'] not in ['Phishing', 'Legitimate']:\n        return False, f\"Invalid classification: {result['classification']}\"\n    \n    is_phishing_matches = (result['is_phishing'] and result['classification'] == 'Phishing') or \\\n                          (not result['is_phishing'] and result['classification'] == 'Legitimate')\n    if not is_phishing_matches:\n        return False, \"is_phishing and classification fields don't match\"\n    \n    return True, \"Valid\"\n\ndef check_with_gemini(domain):\n    \"\"\"Check domain credibility using Google Gemini API with comprehensive validation\"\"\"\n    if not gemini_model:\n        return None, \"Gemini API not available\"\n    \n    try:\n        prompt = f\"\"\"Analyze this domain for phishing indicators: {domain}\n\nPlease evaluate if this domain is legitimate or potentially a phishing domain. Consider:\n1. Character substitutions (like 0 for O, 1 for l)\n2. Suspicious keywords (login, verify, secure, account)\n3. Domain structure and patterns\n4. Known legitimate domains\n5. TLD (top-level domain) reputation\n\nRespond ONLY in valid JSON format with:\n{{\n  \"is_phishing\": true/false,\n  \"confidence\": 0-100,\n  \"reasons\": [\"reason1\", \"reason2\", \"reason3\"],\n  \"classification\": \"Phishing\" or \"Legitimate\"\n}}\n\nImportant: Provide at least 2-3 specific reasons for your classification.\"\"\"\n\n        response = gemini_model.generate_content(prompt)\n        \n        if not response or not response.text:\n            return None, \"Empty response from Gemini API\"\n        \n        import json\n        result_text = response.text.strip()\n        \n        if result_text.startswith('```json'):\n            result_text = result_text[7:-3].strip()\n        elif result_text.startswith('```'):\n            result_text = result_text[3:-3].strip()\n        \n        try:\n            result = json.loads(result_text)\n        except json.JSONDecodeError as je:\n            return None, f\"Invalid JSON response: {str(je)}\"\n        \n        is_valid, validation_msg = validate_gemini_response(result)\n        if not is_valid:\n            return None, f\"Invalid response format: {validation_msg}\"\n        \n        print(f\"✓ Gemini API validated: {domain} -> {result['classification']} ({result['confidence']}%)\")\n        return result, None\n        \n    except Exception as e:\n        error_msg = str(e)\n        if 'quota' in error_msg.lower() or 'rate' in error_msg.lower():\n            return None, f\"API quota exceeded: {error_msg}\"\n        elif 'api key' in error_msg.lower():\n            return None, \"Invalid API key\"\n        return None, f\"API error: {error_msg}\"\n\nclass AdvancedDomainChecker:\n    def __init__(self, target_domain):\n        self.target_domain = target_domain\n        self.target_parts = tldextract.extract(self.target_domain)\n        \n    def is_legitimate_domain(self, domain):\n        \"\"\"Check the domain legitimacy using multiple verification methods\"\"\"\n        check_score = 0\n        reasons = []\n        \n        parts = tldextract.extract(domain)\n\n        if parts.registered_domain != self.target_parts.registered_domain:\n            check_score += 1\n            reasons.append(\"Different registered domain\")\n        \n        ssl_valid, ssl_reason = self.has_valid_ssl_certificate(domain)\n        if not ssl_valid:\n            check_score += 1\n            reasons.append(f\"SSL Issue: {ssl_reason}\")\n        \n        auth_valid, auth_reason = self.has_domain_authentication(parts.registered_domain)\n        if not auth_valid:\n            check_score += 1\n            reasons.append(f\"Domain auth issue: {auth_reason}\")\n\n        registration_valid, reg_reason = self.has_legitimate_registration(domain)\n        if not registration_valid:\n            check_score += 1\n            reasons.append(f\"Registration issue: {reg_reason}\")\n        \n        if check_score == 0:\n            return True, \"Domain appears legitimate\"\n        else:\n            return False, \"; \".join(reasons)\n            \n    def has_valid_ssl_certificate(self, domain, port=443):\n        \"\"\"Check if the domain has valid SSL certificate from trusted CA\"\"\"\n        try:\n            context = ssl.create_default_context()\n            with socket.create_connection((domain, port), timeout=5) as sock:\n                with context.wrap_socket(sock, server_hostname=domain) as ssock:\n                    cert = ssock.getpeercert()\n\n                if not cert:\n                    return False, \"No SSL certificate found\"\n                \n                not_after = datetime.strptime(cert['notAfter'], '%b %d %H:%M:%S %Y %Z')\n                if datetime.now() > not_after:\n                    return False, \"SSL certificate expired\"\n\n                org_name = None\n                if 'subject' in cert:\n                    for field in cert['subject']:\n                        if field[0][0] == 'organizationName':\n                            org_name = field[0][1]\n                            break\n\n                if org_name and (\"education\" in org_name.lower() or \"college\" in org_name.lower() \n                                or \"university\" in org_name.lower() or \"gndec\" in org_name.lower()):\n                    return True, f\"Valid educational certificate: {org_name}\"\n                \n                return True, \"Valid SSL certificate\"\n        except Exception as e:\n            return False, f\"SSL connection failed: {str(e)}\"\n    \n    def has_domain_authentication(self, domain):\n        \"\"\"Check for domain authentication records that legitimate organizations typically implement\"\"\"\n        try:\n            dmarc_record = f\"_dmarc.{domain}\"\n            try:\n                answers = dns.resolver.resolve(dmarc_record, 'TXT')\n                for rdata in answers:\n                    if 'v=DMARC1' in str(rdata):\n                        return True, \"DMARC record found\"\n            except:\n                pass\n\n            try:\n                answers = dns.resolver.resolve(domain, 'TXT')\n                for rdata in answers:\n                    if 'v=spf1' in str(rdata):\n                        return True, \"SPF record found\"\n            except:\n                pass\n\n            return False, \"No domain authentication records found\"\n        except Exception as e:\n            return False, f\"DNS checks failed: {str(e)}\"\n    \n    def has_legitimate_registration(self, domain):\n        \"\"\"Check WHOIS information for legitimate registration details\"\"\"\n        try:\n            w = whois.whois(domain)\n            \n            if w.creation_date:\n                if isinstance(w.creation_date, list):\n                    creation_date = w.creation_date[0]\n                else:\n                    creation_date = w.creation_date\n\n                if isinstance(creation_date, str):\n                    try:\n                        creation_date = datetime.strptime(str(creation_date), '%Y-%m-%d %H:%M:%S')\n                    except:\n                        try:\n                            creation_date = datetime.strptime(str(creation_date), '%d-%b-%Y')\n                        except:\n                            return True, \"Could not parse creation date\"\n                elif not isinstance(creation_date, datetime):\n                    return True, \"Could not parse creation date\"\n\n                domain_age = (datetime.now() - creation_date).days\n                if domain_age < 30:\n                    return False, f\"Domain is very new ({domain_age} days)\"\n\n            if domain.endswith('.edu') or domain.endswith('.ac.in'):\n                return True, \"Educational domain detected\"\n\n            return True, \"Domain registration appears legitimate\"\n        except Exception as e:\n            return False, f\"WHOIS check failed: {str(e)}\"\n\nclass PhishingDetector:\n    def __init__(self, target_domain):\n        self.target_domain = target_domain\n        self.checker = AdvancedDomainChecker(target_domain)\n        self.user_agent = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36\"\n        self.session = requests.Session()\n        self.session.headers.update({\"User-Agent\": self.user_agent})\n        \n    def generate_domain_variations(self):\n        \"\"\"Generate potential phishing domains using various techniques\"\"\"\n        variations = set()\n        domain_parts = tldextract.extract(self.target_domain)\n        base_domain = f\"{domain_parts.domain}.{domain_parts.suffix}\"\n        \n        prefixes = ['login', 'signin', 'verify', 'secure', 'account', 'auth']\n        suffixes = ['login', 'signin', 'verify', 'secure', 'account', 'auth']\n        \n        for prefix in prefixes:\n            variations.add(f\"{prefix}-{base_domain}\")\n            variations.add(f\"{prefix}.{base_domain}\")\n            variations.add(f\"{prefix}{base_domain}\")\n            \n        for suffix in suffixes:\n            variations.add(f\"{base_domain}-{suffix}\")\n            variations.add(f\"{base_domain}.{suffix}\")\n            variations.add(f\"{base_domain}{suffix}\")\n            \n        if domain_parts.suffix == 'com':\n            for tld in ['net', 'org', 'info', 'biz']:\n                variations.add(f\"{domain_parts.domain}.{tld}\")\n                \n        return variations\n        \n    def get_suspicious_domains(self):\n        \"\"\"Get all suspicious domains from various sources\"\"\"\n        print(\"Searching for suspicious domains...\")\n        \n        generated_domains = self.generate_domain_variations()\n        print(f\"Generated {len(generated_domains)} domain variations\")\n        \n        valid_domains = []\n        for domain in generated_domains:\n            if self.validate_domain_exists(domain):\n                valid_domains.append(domain)\n                \n        print(f\"Found {len(valid_domains)} valid domains to check\")\n        return valid_domains\n        \n    def validate_domain_exists(self, domain):\n        \"\"\"Check if a domain actually exists by resolving DNS\"\"\"\n        try:\n            dns.resolver.resolve(domain, 'A')\n            return True\n        except:\n            return False\n            \n    def analyze_domain(self, domain):\n        \"\"\"Analyze a single domain for phishing indicators\"\"\"\n        risk_factors = []\n        final_url = domain\n        title = \"\"\n        \n        is_legitimate, reason = self.checker.is_legitimate_domain(domain)\n        if not is_legitimate:\n            risk_factors.append(f\"Legitimacy check failed: {reason}\")\n        \n        try:\n            response = self.session.get(f\"https://{domain}\", timeout=10, allow_redirects=True)\n            final_url = response.url\n            content = response.text\n            \n            soup = BeautifulSoup(content, 'html.parser')\n            \n            title_tag = soup.find('title')\n            if title_tag:\n                title = title_tag.get_text().strip()\n                \n            login_forms = soup.find_all('form')\n            for form in login_forms:\n                inputs = form.find_all('input')\n                has_password = any(input.get('type') == 'password' for input in inputs)\n                has_username = any(input.get('type') in ['text', 'email'] for input in inputs)\n                \n                if has_password and has_username:\n                    risk_factors.append(\"Contains login form with username and password fields\")\n                    break\n            \n            suspicious_keywords = ['login', 'signin', 'verify', 'account', 'security']\n            content_lower = content.lower()\n            \n            if title:\n                title_lower = title.lower()\n                if any(keyword in title_lower for keyword in suspicious_keywords):\n                    risk_factors.append(\"Uses suspicious keywords in title\")\n            \n            keyword_count = 0\n            for keyword in suspicious_keywords:\n                if keyword in content_lower:\n                    keyword_count += 1\n            \n            if keyword_count > 3:\n                risk_factors.append(f\"Uses multiple ({keyword_count}) suspicious keywords in content\")\n                \n            target_clean = self.target_domain.replace('www.', '').replace('.com', '')\n            domain_clean = domain.replace('www.', '').replace('.com', '')\n            \n            similarity = lev_distance(target_clean, domain_clean)\n            if similarity <= 2:\n                risk_factors.append(f\"Very similar to target domain (distance: {similarity})\")\n                \n        except Exception as e:\n            risk_factors.append(f\"Cannot access website: {str(e)}\")\n        \n        risk_level = self.determine_risk_level(risk_factors)\n        \n        return risk_factors, final_url, title, risk_level\n        \n    def determine_risk_level(self, risk_factors):\n        \"\"\"Determine risk level based on factors found\"\"\"\n        if not risk_factors:\n            return \"Low\"\n        \n        high_risk_indicators = [\n            \"SSL certificate is invalid or expired\",\n            \"Contains login form with username and password fields\",\n            \"Legitimacy check failed:\"\n        ]\n        \n        medium_risk_indicators = [\n            \"Uses HTTP instead of HTTPS\",\n            \"Uses multiple (\",\n            \"Recently registered domain (\",\n            \"Very similar to target domain\"\n        ]\n        \n        high_count = sum(1 for factor in risk_factors if any(indicator in factor for indicator in high_risk_indicators))\n        medium_count = sum(1 for factor in risk_factors if any(indicator in factor for indicator in medium_risk_indicators))\n        \n        if high_count > 0:\n            return \"High\"\n        elif medium_count > 1 or (medium_count > 0 and len(risk_factors) > 2):\n            return \"Medium\"\n        else:\n            return \"Low\"\n\n@app.route('/')\ndef index():\n    return render_template('index.html')\n\n@app.route('/analyze', methods=['POST'])\ndef analyze():\n    target_domain = request.form.get('domain')\n    if not target_domain:\n        return jsonify({'success': False, 'error': 'Please enter a domain name'})\n    \n    if not target_domain.startswith(('http://', 'https://')):\n        target_domain = 'https://' + target_domain\n    \n    parsed_domain = urlparse(target_domain)\n    netloc = parsed_domain.netloc or parsed_domain.path\n    \n    analysis_id = str(uuid.uuid4())\n    \n    analysis_results[analysis_id] = {\n        'target_domain': netloc,\n        'status': 'processing',\n        'progress': 0,\n        'results': [],\n        'start_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n        'end_time': None,\n        'total_domains': 0,\n        'processed_domains': 0\n    }\n    \n    thread = threading.Thread(target=run_analysis, args=(netloc, analysis_id))\n    thread.daemon = True\n    thread.start()\n    \n    return jsonify({\n        'success': True,\n        'analysis_id': analysis_id,\n        'redirect_url': f'/results/{analysis_id}'\n    })\n\ndef run_analysis(target_domain, analysis_id):\n    \"\"\"Run the analysis and store results with progress updates\"\"\"\n    detector = PhishingDetector(target_domain)\n    \n    analysis_results[analysis_id]['status'] = 'searching_domains'\n    analysis_results[analysis_id]['progress'] = 20\n    \n    suspicious_domains = detector.get_suspicious_domains()\n    \n    if not suspicious_domains:\n        analysis_results[analysis_id]['status'] = 'completed'\n        analysis_results[analysis_id]['progress'] = 100\n        analysis_results[analysis_id]['end_time'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n        return\n    \n    analysis_results[analysis_id]['status'] = 'analyzing_domains'\n    analysis_results[analysis_id]['progress'] = 40\n    analysis_results[analysis_id]['total_domains'] = len(suspicious_domains)\n    analysis_results[analysis_id]['processed_domains'] = 0\n    \n    results = []\n    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n        future_to_domain = {executor.submit(detector.analyze_domain, domain): domain for domain in suspicious_domains}\n        \n        for i, future in enumerate(concurrent.futures.as_completed(future_to_domain)):\n            domain = future_to_domain[future]\n            try:\n                risk_factors, final_url, title, risk_level = future.result()\n                \n                if risk_factors:\n                    results.append({\n                        \"domain\": domain,\n                        \"url\": final_url,\n                        \"title\": title,\n                        \"risk_factors\": risk_factors,\n                        \"risk_level\": risk_level\n                    })\n                \n                analysis_results[analysis_id]['processed_domains'] = i + 1\n                analysis_results[analysis_id]['progress'] = 40 + (i / len(suspicious_domains)) * 60\n                analysis_results[analysis_id]['results'] = results\n                \n            except Exception as e:\n                print(f\"Error analyzing {domain}: {e}\")\n    \n    analysis_results[analysis_id]['status'] = 'completed'\n    analysis_results[analysis_id]['progress'] = 100\n    analysis_results[analysis_id]['results'] = results\n    analysis_results[analysis_id]['end_time'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n\n@app.route('/results/<analysis_id>')\ndef results(analysis_id):\n    if analysis_id not in analysis_results:\n        return redirect(url_for('index'))\n    \n    return render_template('results.html', analysis_id=analysis_id)\n\n@app.route('/api/analysis/<analysis_id>')\ndef get_analysis(analysis_id):\n    if analysis_id not in analysis_results:\n        return jsonify({'error': 'Analysis not found'}), 404\n    \n    return jsonify(analysis_results[analysis_id])\n\n@app.route('/check-domain', methods=['POST'])\ndef check_domain():\n    \"\"\"Check a single domain for legitimacy\"\"\"\n    data = request.get_json()\n    domain = data.get('domain')\n    target_domain = data.get('target_domain')\n    \n    if not domain or not target_domain:\n        return jsonify({'error': 'Domain and target domain are required'}), 400\n    \n    checker = AdvancedDomainChecker(target_domain)\n    is_legitimate, reason = checker.is_legitimate_domain(domain)\n    \n    return jsonify({\n        'domain': domain,\n        'is_legitimate': is_legitimate,\n        'reason': reason\n    })\n\ndef cross_validate_results(domain, gemini_result, ml_prediction, ml_probability):\n    \"\"\"Cross-validate Gemini and ML model results for consistency\"\"\"\n    gemini_is_phishing = gemini_result.get('is_phishing', False)\n    gemini_confidence = gemini_result.get('confidence', 0)\n    \n    ml_is_phishing = bool(ml_prediction == 1)\n    ml_confidence = float(ml_probability[int(ml_prediction)]) * 100\n    \n    agreement = gemini_is_phishing == ml_is_phishing\n    \n    validation_result = {\n        'agreement': agreement,\n        'gemini_classification': 'Phishing' if gemini_is_phishing else 'Legitimate',\n        'ml_classification': 'Phishing' if ml_is_phishing else 'Legitimate',\n        'gemini_confidence': gemini_confidence,\n        'ml_confidence': ml_confidence,\n        'confidence_difference': abs(gemini_confidence - ml_confidence)\n    }\n    \n    if agreement:\n        validation_result['status'] = 'Both models agree'\n        if abs(gemini_confidence - ml_confidence) < 20:\n            validation_result['reliability'] = 'High'\n        else:\n            validation_result['reliability'] = 'Medium'\n    else:\n        validation_result['status'] = 'Models disagree - requires manual review'\n        validation_result['reliability'] = 'Low'\n        validation_result['warning'] = f\"Gemini says {validation_result['gemini_classification']}, ML says {validation_result['ml_classification']}\"\n    \n    print(f\"Cross-validation for {domain}: {validation_result['status']} (Reliability: {validation_result['reliability']})\")\n    return validation_result\n\n@app.route('/ml-detect', methods=['POST'])\ndef ml_detect():\n    \"\"\"Detect phishing domain using Gemini API with ML model fallback and cross-validation\"\"\"\n    data = request.get_json()\n    domain = data.get('domain')\n    \n    if not domain:\n        return jsonify({'error': 'Domain is required'}), 400\n    \n    domain_clean = domain.replace('http://', '').replace('https://', '').split('/')[0]\n    \n    gemini_result, gemini_error = check_with_gemini(domain_clean)\n    features = extract_ml_features(domain_clean)\n    \n    if gemini_result and ml_model:\n        try:\n            feature_columns = ['length', 'has_digit', 'has_hyphen', 'num_dots', 'num_digits', 'suspicious_keywords', 'tld_length', 'subdomain_count']\n            feature_values = [features[col] for col in feature_columns]\n            \n            ml_prediction = ml_model.predict([feature_values])[0]\n            ml_probability = ml_model.predict_proba([feature_values])[0]\n            \n            cross_validation = cross_validate_results(domain_clean, gemini_result, ml_prediction, ml_probability)\n            \n            result = {\n                'domain': domain_clean,\n                'is_phishing': gemini_result.get('is_phishing', False),\n                'confidence': float(gemini_result.get('confidence', 0)),\n                'classification': gemini_result.get('classification', 'Unknown'),\n                'reasons': gemini_result.get('reasons', []),\n                'detection_method': 'Google Gemini API (Cross-validated with ML)',\n                'features': features,\n                'cross_validation': cross_validation\n            }\n            return jsonify(result)\n        except Exception as e:\n            print(f\"Cross-validation failed: {e}\")\n    \n    if gemini_result:\n        result = {\n            'domain': domain_clean,\n            'is_phishing': gemini_result.get('is_phishing', False),\n            'confidence': float(gemini_result.get('confidence', 0)),\n            'classification': gemini_result.get('classification', 'Unknown'),\n            'reasons': gemini_result.get('reasons', []),\n            'detection_method': 'Google Gemini API',\n            'features': features\n        }\n        return jsonify(result)\n    \n    if ml_model is None:\n        return jsonify({\n            'error': 'Both Gemini API and ML model unavailable',\n            'gemini_error': gemini_error\n        }), 500\n    \n    try:\n        features = extract_ml_features(domain_clean)\n        feature_columns = ['length', 'has_digit', 'has_hyphen', 'num_dots', 'num_digits', 'suspicious_keywords', 'tld_length', 'subdomain_count']\n        feature_values = [features[col] for col in feature_columns]\n        \n        prediction = ml_model.predict([feature_values])[0]\n        probability = ml_model.predict_proba([feature_values])[0]\n        \n        is_phishing = bool(prediction == 1)\n        confidence = float(probability[int(prediction)]) * 100\n        \n        result = {\n            'domain': domain_clean,\n            'is_phishing': is_phishing,\n            'confidence': confidence,\n            'classification': 'Phishing' if is_phishing else 'Legitimate',\n            'detection_method': 'ML Model (Fallback)',\n            'gemini_error': gemini_error,\n            'features': features\n        }\n        \n        return jsonify(result)\n    \n    except Exception as e:\n        return jsonify({'error': f'Error processing domain: {str(e)}'}), 500\n\n@app.route('/batch-detect', methods=['POST'])\ndef batch_detect():\n    \"\"\"Batch detect phishing domains using Gemini API with ML model fallback\"\"\"\n    if 'file' not in request.files:\n        return jsonify({'error': 'No file uploaded'}), 400\n    \n    file = request.files['file']\n    if file.filename == '':\n        return jsonify({'error': 'No file selected'}), 400\n    \n    if not file.filename.endswith(('.xlsx', '.xls')):\n        return jsonify({'error': 'File must be Excel format (.xlsx or .xls)'}), 400\n    \n    try:\n        df = pd.read_excel(file)\n        \n        if 'domain' not in df.columns:\n            return jsonify({'error': 'Excel file must have a \"domain\" column'}), 400\n        \n        results = []\n        gemini_count = 0\n        ml_count = 0\n        \n        for domain in df['domain']:\n            domain_clean = str(domain).replace('http://', '').replace('https://', '').split('/')[0]\n            \n            gemini_result, gemini_error = check_with_gemini(domain_clean)\n            \n            if gemini_result:\n                results.append({\n                    'domain': domain_clean,\n                    'is_phishing': gemini_result.get('is_phishing', False),\n                    'confidence': float(gemini_result.get('confidence', 0)),\n                    'classification': gemini_result.get('classification', 'Unknown'),\n                    'detection_method': 'Gemini API'\n                })\n                gemini_count += 1\n            elif ml_model:\n                features = extract_ml_features(domain_clean)\n                feature_columns = ['length', 'has_digit', 'has_hyphen', 'num_dots', 'num_digits', 'suspicious_keywords', 'tld_length', 'subdomain_count']\n                feature_values = [features[col] for col in feature_columns]\n                \n                prediction = ml_model.predict([feature_values])[0]\n                probability = ml_model.predict_proba([feature_values])[0]\n                \n                is_phishing = bool(prediction == 1)\n                confidence = float(probability[int(prediction)]) * 100\n                \n                results.append({\n                    'domain': domain_clean,\n                    'is_phishing': is_phishing,\n                    'confidence': confidence,\n                    'classification': 'Phishing' if is_phishing else 'Legitimate',\n                    'detection_method': 'ML Model'\n                })\n                ml_count += 1\n            else:\n                results.append({\n                    'domain': domain_clean,\n                    'error': 'Both Gemini API and ML model unavailable'\n                })\n        \n        return jsonify({\n            'results': results, \n            'total': len(results),\n            'gemini_count': gemini_count,\n            'ml_count': ml_count\n        })\n    \n    except Exception as e:\n        return jsonify({'error': f'Error processing file: {str(e)}'}), 500\n\nif __name__ == '__main__':\n    app.run(host='0.0.0.0', port=5000, debug=True, threaded=True)\n","size_bytes":29078},"replit.md":{"content":"# Phishing Domain Detector\n\n## Overview\n\nA Flask-based web application that detects and analyzes potential phishing domains through comprehensive security checks, SSL validation, domain authentication, and AI/ML-powered content analysis. The system uses Google Gemini API with a RandomForest ML fallback to provide intelligent phishing detection with detailed risk assessment.\n\n## Recent Changes (October 3, 2025)\n\n### GitHub Import Setup - Completed\n- **Python Environment**: Python 3.11 installed and configured\n- **Dependencies**: Successfully installed all required packages from requirements.txt (Flask, scikit-learn, pandas, google-generativeai, and all other dependencies)\n- **Requirements Cleanup**: Removed duplicate entries from requirements.txt for cleaner package management\n- **Workflow Configuration**: Set up Flask App workflow to run on `0.0.0.0:5000` with webview output\n- **Deployment Configuration**: Configured production deployment with Gunicorn using autoscale deployment target with 4 workers and 120-second timeout\n- **Application Status**: Successfully running and tested - frontend loads correctly\n\n### Environment Setup\n- **Development Server**: Flask development server running on port 5000 with debug mode enabled\n- **Production Server**: Gunicorn configured with 4 workers, port reuse, and extended timeout for long-running domain checks\n- **ML Model**: phishing_model.pkl loaded successfully on startup\n- **API Integration**: Google Gemini API ready (requires GOOGLE_API_KEY environment variable to be set by user)\n\n### Configuration Notes\n- To use Google Gemini API for advanced AI-powered detection, add GOOGLE_API_KEY to environment variables\n- Without API key, application automatically falls back to RandomForest ML model\n\n## User Preferences\n\nPreferred communication style: Simple, everyday language.\n\n## System Architecture\n\n### Core Application Framework\n\n**Flask Web Application**: The system is built on Flask 2.3.3, following a traditional server-side rendering pattern with:\n- Route handlers in `app.py` for domain analysis and results display\n- Session-based state management for analysis results storage\n- Template rendering with Bootstrap 5 for responsive UI\n- RESTful API endpoints for programmatic access (ML detection endpoints)\n\n**Deployment Strategy**: Configured for both development (`python app.py`) and production (Gunicorn with autoscaling), binding to `0.0.0.0:5000` for web accessibility.\n\n### AI/ML Detection Architecture\n\n**Dual-Layer Intelligence System**: The application implements a smart fallback mechanism:\n\n1. **Primary**: Google Gemini API (`gemini-2.0-flash-exp`) for advanced AI-powered phishing detection with natural language reasoning\n2. **Fallback**: RandomForest ML classifier (100% accuracy on training set) loaded from `phishing_model.pkl`\n\n**Feature Engineering**: Domain analysis extracts structural features including:\n- Domain length, digit count, hyphen presence\n- Keyword analysis for phishing indicators\n- String similarity detection using Levenshtein distance\n- Multi-threaded concurrent analysis for performance\n\n### Domain Validation Pipeline\n\n**Multi-Layer Security Checks**: The system performs comprehensive validation through:\n\n1. **SSL Certificate Analysis**: Validates certificates against trusted Certificate Authorities\n2. **Domain Authentication**: Checks DMARC, SPF, and DNS security records using `dnspython`\n3. **WHOIS Analysis**: Examines domain registration age and ownership details\n4. **Content Scanning**: BeautifulSoup-based HTML parsing for phishing pattern detection\n5. **Similarity Detection**: Jellyfish library for domain spoofing identification\n\n**Result Aggregation**: Analysis results stored in-memory dictionary with UUID-based session tracking, providing risk classification (High/Medium/Low).\n\n### Data Processing\n\n**Batch Analysis**: Supports Excel file uploads for multi-domain analysis using pandas and openpyxl, enabling enterprise-scale phishing detection workflows.\n\n**Model Training**: ML model trained on 70-domain dataset (35 legitimate, 35 phishing) using scikit-learn, achieving perfect accuracy on test set.\n\n## External Dependencies\n\n### AI/ML Services\n- **Google Gemini API**: Primary AI detection service (requires `GOOGLE_API_KEY` environment variable)\n- **scikit-learn**: RandomForest ML model training and inference\n- **pandas**: Excel data processing and feature extraction\n- **openpyxl**: Excel file I/O operations\n\n### Security & Network Libraries\n- **tldextract**: Top-level domain parsing and extraction\n- **python-whois**: WHOIS protocol implementation\n- **dnspython**: DNS record resolution and validation\n- **requests**: HTTP client for domain accessibility checks\n- **beautifulsoup4**: HTML parsing and content analysis\n\n### Utility Libraries\n- **jellyfish**: String similarity algorithms (Levenshtein distance)\n- **Flask**: Web framework with session management\n- **Gunicorn**: Production WSGI server with autoscaling\n\n### Frontend Stack\n- **Bootstrap 5.1.3**: Responsive UI framework\n- **Font Awesome 6.0.0**: Icon library\n- **Native JavaScript**: Form handling and API interactions","size_bytes":5127},"load_kaggle_dataset.py":{"content":"import kagglehub\nimport pandas as pd\nimport os\n\ndef load_phishing_dataset():\n    \"\"\"Load phishing dataset from Kaggle\"\"\"\n    print(\"Downloading phishing dataset from Kaggle...\")\n    \n    try:\n        path = kagglehub.dataset_download(\"taruntiwarihp/phishing-site-urls\")\n        print(f\"Dataset downloaded to: {path}\")\n        \n        csv_files = [f for f in os.listdir(path) if f.endswith('.csv')]\n        print(f\"Found CSV files: {csv_files}\")\n        \n        if not csv_files:\n            print(\"No CSV files found in the dataset\")\n            return None\n        \n        csv_path = os.path.join(path, csv_files[0])\n        print(f\"Loading: {csv_path}\")\n        \n        df = pd.read_csv(csv_path)\n        \n        print(f\"\\nDataset loaded successfully!\")\n        print(f\"Total records: {len(df)}\")\n        print(f\"Columns: {df.columns.tolist()}\")\n        print(\"\\nFirst 5 records:\")\n        print(df.head())\n        \n        print(\"\\nDataset info:\")\n        print(df.info())\n        \n        print(\"\\nLabel distribution:\")\n        if 'Label' in df.columns:\n            print(df['Label'].value_counts())\n        \n        df.to_csv('kaggle_phishing_dataset.csv', index=False)\n        print(\"\\nDataset saved to: kaggle_phishing_dataset.csv\")\n        \n        return df\n        \n    except Exception as e:\n        print(f\"Error loading dataset: {e}\")\n        print(\"\\nNote: You may need to authenticate with Kaggle.\")\n        print(\"Set up Kaggle API credentials:\")\n        print(\"1. Go to https://www.kaggle.com/account\")\n        print(\"2. Create an API token (downloads kaggle.json)\")\n        print(\"3. Set KAGGLE_USERNAME and KAGGLE_KEY environment variables\")\n        return None\n\nif __name__ == \"__main__\":\n    df = load_phishing_dataset()\n","size_bytes":1747}},"version":1}